{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa61de13",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with NLP: Tweets/Reviews\n",
    "\n",
    "This notebook demonstrates data preprocessing, model training, and insights for sentiment analysis on short texts (e.g., tweets, reviews)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c549b8",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Install/import required libraries. If needed, uncomment `pip install` lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd207c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on a fresh environment, uncomment the line below\n",
    "# !pip install numpy pandas scikit-learn matplotlib nbformat\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d580b0",
   "metadata": {},
   "source": [
    "## 2. Data: Synthetic Tweets/Reviews\n",
    "We create a small labeled dataset with positive, negative, and neutral examples (with slang and emojis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np, pandas as pd\n",
    "\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "positive_phrases = [\n",
    "    \"Absolutely loved this!\", \"What a fantastic experience\", \"superb quality\", \"highly recommend\",\n",
    "    \"this made my day\", \"brilliant work\", \"five stars\", \"chef's kiss\", \"awesome service\",\n",
    "    \"worth every rupee\", \"top notch\", \"movie was amazing\", \"battery life is great\",\n",
    "    \"performance is blazing fast\", \"UI is clean and smooth\", \"updates are timely\",\n",
    "    \"camera is excellent\", \"support team was helpful\", \"value for money\", \"gonna buy again\",\n",
    "]\n",
    "negative_phrases = [\n",
    "    \"Terrible experience\", \"really disappointed\", \"waste of money\", \"never again\",\n",
    "    \"this ruined my day\", \"worst service ever\", \"one star\", \"bugs everywhere\",\n",
    "    \"not worth it\", \"battery drains so fast\", \"performance is awful\",\n",
    "    \"UI is laggy\", \"kept crashing\", \"support didn't respond\",\n",
    "    \"overpriced junk\", \"quality is poor\", \"delivery was late\", \"sound is bad\",\n",
    "    \"totally useless\", \"refund please\",\n",
    "]\n",
    "neutral_phrases = [\n",
    "    \"It arrived yesterday\", \"Using it for a week now\", \"I watched the movie today\",\n",
    "    \"setup took around 10 minutes\", \"package includes charger and cable\",\n",
    "    \"UI changed after update\", \"price dropped last month\", \"service center is nearby\",\n",
    "    \"received a message\", \"there was an announcement\", \"I went to the store\",\n",
    "    \"battery shows 80 percent\", \"new features added\", \"some settings were hidden\",\n",
    "    \"works as expected\", \"layout is different\", \"I saw the trailer\", \"download completed\",\n",
    "    \"stock is available\", \"return window closes soon\",\n",
    "]\n",
    "\n",
    "emojis_pos = [\"üòç\", \"ü§©\", \"üî•\", \"‚ú®\", \"üëç\", \"üòä\"]\n",
    "emojis_neg = [\"üò°\", \"ü§Æ\", \"üëé\", \"üíÄ\", \"üò§\", \"üò≠\"]\n",
    "emojis_neu = [\"ü§î\", \"üßê\", \"‚ÑπÔ∏è\", \"üì¶\", \"üïí\", \"üì£\"]\n",
    "\n",
    "extra_tokens = [\"pls\", \"bro\", \"yaar\", \"lol\", \"fr\", \"ngl\", \"btw\", \"imo\", \"tbh\", \"idk\", \"sale\", \"offer\"]\n",
    "\n",
    "def synth_line(pool, emoji_pool, extra_tokens):\n",
    "    import random\n",
    "    base = random.choice(pool)\n",
    "    em = random.choice(emoji_pool)\n",
    "    noise = \" \" + \" \".join(random.sample(extra_tokens, k=random.randint(0, 2))) if extra_tokens else \"\"\n",
    "    return f\"{base} {em}{noise}\"\n",
    "\n",
    "def make_samples(n, phrases, emojis):\n",
    "    return [synth_line(phrases, emojis, extra_tokens) for _ in range(n)]\n",
    "\n",
    "n_per_class = 60\n",
    "texts = make_samples(n_per_class, positive_phrases, emojis_pos) +         make_samples(n_per_class, negative_phrases, emojis_neg) +         make_samples(n_per_class, neutral_phrases, emojis_neu)\n",
    "labels = ([\"positive\"] * n_per_class) + ([\"negative\"] * n_per_class) + ([\"neutral\"] * n_per_class)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"text\": texts, \"label\": labels}).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ac797",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values, df['label'].values,\n",
    "    test_size=0.25, random_state=42, stratify=df['label'].values\n",
    ")\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3fc4c",
   "metadata": {},
   "source": [
    "## 4. Pipeline: TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbaaa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=1, max_df=0.95)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, multi_class='auto'))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b2532",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f240794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "preds = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "pr, rc, f1, support = precision_recall_fscore_support(\n",
    "    y_test, preds, labels=['negative', 'neutral', 'positive'], zero_division=0\n",
    ")\n",
    "metrics_df = pd.DataFrame({\n",
    "    'class': ['negative', 'neutral', 'positive'],\n",
    "    'precision': pr, 'recall': rc, 'f1': f1, 'support': support\n",
    "})\n",
    "metrics_df.loc[len(metrics_df)] = ['overall_accuracy', acc, np.nan, np.nan, len(y_test)]\n",
    "metrics_df.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba155d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50a015",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21704ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_test, preds, labels=['negative', 'neutral', 'positive'])\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.xticks(ticks=[0,1,2], labels=['negative','neutral','positive'])\n",
    "plt.yticks(ticks=[0,1,2], labels=['negative','neutral','positive'])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437c7cd",
   "metadata": {},
   "source": [
    "## 6. Insights: Most-Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb868d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "tfidf = pipeline.named_steps['tfidf']\n",
    "clf = pipeline.named_steps['clf']\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "class_to_index = {c: i for i, c in enumerate(clf.classes_)}\n",
    "\n",
    "def top_features_for_class(class_index, k=15):\n",
    "    coefs = clf.coef_[class_index]\n",
    "    top_idx = np.argsort(coefs)[-k:][::-1]\n",
    "    return pd.DataFrame({'feature': feature_names[top_idx], 'weight': coefs[top_idx]})\n",
    "\n",
    "top_pos = top_features_for_class(class_to_index['positive'], 15)\n",
    "top_neg = top_features_for_class(class_to_index['negative'], 15)\n",
    "top_neu = top_features_for_class(class_to_index['neutral'], 15)\n",
    "\n",
    "print(\"Top Positive Features:\"); display(top_pos)\n",
    "print(\"\\nTop Negative Features:\"); display(top_neg)\n",
    "print(\"\\nTop Neutral Features:\"); display(top_neu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3a854",
   "metadata": {},
   "source": [
    "## 7. Try It: Predict Your Own Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b54beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"Loved the new update, super smooth!\",\n",
    "    \"Battery drains in 2 hours, not happy\",\n",
    "    \"The package arrived on Tuesday and I set it up\"\n",
    "]\n",
    "print(list(zip(samples, pipeline.predict(samples))))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
